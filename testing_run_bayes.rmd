---
title: "Testing to develop objective functions with the correct structure to match existing work and run seamlessly; Part 1 - figure out run_bayes"
author: "ACS"
date: "5/21/2020"
output: 
  html_document:
      toc: true
      toc_float: true
      toc_depth: 4
      number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gcamland)
```

# Motivation

- added a  truncated function `run_ensemble_no_bayes` that stops before `run_bayes` portion in `run_ensemble`
- will remove the `run_ensemble_no_bayes` function from final PR.
- added a print statement in `run_ensemble` when `run_bayes` is run.

TODO: figure out N=2 vs N=4

# Setup params

Pick the number of runs to do

```{r}
Nruns <- 2
Ncompare <- 9 # one of the 10 runs to do specific comparison of
```

# Do run with truncated version of `run_ensemble`

```{r}
# #############################################################################
## Truncate run_ensemble and return
## info that goes into run_bayes
## so can see what the i/o looks like
## to replicate structure with new
## objective functions.
# #############################################################################
set.seed(1)

x <- invisible(run_ensemble_no_bayes(N=Nruns))
# ^ function version that returns before the Bayes analysis is run, ie with
# return(list(rslt, scenObjects, lprior, lpdf, outfile, suffix))
rslt <- x[[1]]
scenObjects <- x[[2]]
lprior <- x[[3]]
lpdf <- x[[4]]
outfile <- x[[5]]
suffix <- x[[6]]

aOutputDir <- "./outputs"
# default output dir from run_ensemble - just copy the default used
# instead out updating the return yet again.

```

# Put the results from truncated run_ensemble through run_bayes
```{r}
# Do the bayes piece
scenObjectsBayes <- run_bayes(scenObjects, lpdf=lpdf, lprior = lprior)


# the rest of the run_ensemble function
## Save the scenario info from the scenarios that we ran
filebase <- paste0("scenario-info", suffix, '_withBayes',".rds")
scenfile <- file.path(aOutputDir, filebase)
saveRDS(scenObjectsBayes, scenfile)

message("Output directory is", aOutputDir)
message("scenario file: ", scenfile)
message("output file: ", outfile)

warnings()

invisible(scenObjectsBayes)
```


# Compare input with output from run_bayes
Compare the raw `scenObjects` that went into `run_bayes` with `scenObjectsBayes` that came out of `run_bayes`

```{r}
# #############################################################################
## Investigate what run_bayes actually adds to scenObjects.
# #############################################################################
# for(Ncompare in 1:10){
  
  print(paste('comparing list entry', Ncompare))
  
  preBayes_i <- x[[2]][[Ncompare]] # should be identical to scenObjects[[Ncompare]], just making sure
# run_bayes didn't somehow touch scenObjects and overwrite anything
  
  postBayes_i <- scenObjectsBayes[[Ncompare]]
  
  
  print(paste('any(names(preBayes_i) != names(postBayes_i)))',
               any(names(preBayes_i) != names(postBayes_i))))
  
  print(paste('any(preBayes_i$mScenarioType != postBayes_i$mScenarioType))',
               any(preBayes_i$mScenarioType != postBayes_i$mScenarioType)))
  
  print(paste('any(preBayes_i$mLogitAgroForest_NonPasture != postBayes_i$mLogitAgroForest_NonPasture))',
               any(preBayes_i$mLogitAgroForest_NonPasture != postBayes_i$mLogitAgroForest_NonPasture)))
  
  print(paste('any(preBayes_i$mLogitCropland != postBayes_i$mLogitCropland))',
               any(preBayes_i$mLogitCropland != postBayes_i$mLogitCropland)))
  
  print(any(preBayes_i$mPointwiseLikelihood != postBayes_i$mPointwiseLikelihood))
  # print(paste('head(preBayes_i$mPointwiseLikelihood)'))
  knitr::kable(head(preBayes_i$mPointwiseLikelihood), format = 'html')
  # print(paste('head(postBayes_i$mPointwiseLikelihood)'))
  knitr::kable(head(postBayes_i$mPointwiseLikelihood), format = 'html')
  
  print(paste('any(preBayes_i$mSerialNumber != postBayes_i$mSerialNumber))',
               any(preBayes_i$mSerialNumber != postBayes_i$mSerialNumber)))
  
  print(paste('any(preBayes_i$mRegion != postBayes_i$mRegion))',
                any(preBayes_i$mRegion != postBayes_i$mRegion)))
  
  print(paste('any(preBayes_i$mShareWeights != postBayes_i$mShareWeights))',
               any(preBayes_i$mShareWeights != postBayes_i$mShareWeights)))
  
  print(paste('any(preBayes_i$mCalibrateShareWt != postBayes_i$mCalibrateShareWt))',
              any(preBayes_i$mCalibrateShareWt != postBayes_i$mCalibrateShareWt)))
  
  print(paste('any(preBayes_i$mExpectationType != postBayes_i$mExpectationType))',
               any(preBayes_i$mExpectationType != postBayes_i$mExpectationType)))
  
  print(paste('any(preBayes_i$mSubRegion != postBayes_i$mSubRegion))',
               any(preBayes_i$mSubRegion != postBayes_i$mSubRegion)))
  
  print(paste('any(preBayes_i$mLogitAgroForest != postBayes_i$mLogitAgroForest))',
               any(preBayes_i$mLogitAgroForest != postBayes_i$mLogitAgroForest)))
  
  print(paste('any(preBayes_i$mLogPost != postBayes_i$mLogPost))',
               any(preBayes_i$mLogPost != postBayes_i$mLogPost)))
  # print(paste('head(preBayes_i$mLogPost)'))
  knitr::kable(head(preBayes_i$mLogPost), format = 'html')
  # print(paste('head(postBayes_i$mLogPost)'))
  knitr::kable(head(postBayes_i$mLogPost), format = 'html')
  
  print(paste('any(preBayes_i$mLinearYears != postBayes_i$mLinearYears))',
               any(preBayes_i$mLinearYears != postBayes_i$mLinearYears)))
  
  print(paste('any(preBayes_i$mLaggedShareOld != postBayes_i$mLaggedShareOld))',
               any(preBayes_i$mLaggedShareOld != postBayes_i$mLaggedShareOld)))
  
  print(paste('any(preBayes_i$mOutputDir != postBayes_i$mOutputDir))',
               any(preBayes_i$mOutputDir != postBayes_i$mOutputDir)))
  
  print(paste('any(preBayes_i$mFileName != postBayes_i$mFileName))',
               any(preBayes_i$mFileName != postBayes_i$mFileName)))
  
  print(paste('any(preBayes_i$mLogitUseDefault != postBayes_i$mLogitUseDefault))',
               any(preBayes_i$mLogitUseDefault != postBayes_i$mLogitUseDefault)))
  
  print(paste('any(preBayes_i$mUseZeroCost != postBayes_i$mUseZeroCost))',
              any(preBayes_i$mUseZeroCost != postBayes_i$mUseZeroCost)))
  
  print(paste('any(preBayes_i$mScenarioName != postBayes_i$mScenarioName)',
              any(preBayes_i$mScenarioName != postBayes_i$mScenarioName)))

```

Based on this truncated version that calls `run_bayes` outside of `run_ensemble`, it looks like `run_bayes` isn't doing anything.


# Do the run witht the original `run_ensemble` that includes `run_bayes`
Do the full run
```{r}
set.seed(1)

fullBayes <- invisible(run_ensemble(N=Nruns))
```

# Comparison
Compare to what came out of the truncated run and then calling `run_bayes` on that.
```{r}
# for(Ncompare in 1:10){
  print(paste('comparing list entry', Ncompare))
  
  fullBayes_i <- fullBayes[[Ncompare]]
  postBayes_i <- scenObjectsBayes[[Ncompare]]
  
  
  print(paste('any(names(fullBayes_i) != names(postBayes_i)))',
               any(names(fullBayes_i) != names(postBayes_i))))
  
  print(paste('any(fullBayes_i$mScenarioType != postBayes_i$mScenarioType))',
               any(fullBayes_i$mScenarioType != postBayes_i$mScenarioType)))
  
  print(paste('any(fullBayes_i$mLogitAgroForest_NonPasture != postBayes_i$mLogitAgroForest_NonPasture))',
              any(fullBayes_i$mLogitAgroForest_NonPasture != postBayes_i$mLogitAgroForest_NonPasture)))
  
  print(paste('any(fullBayes_i$mLogitCropland != postBayes_i$mLogitCropland))',
               any(fullBayes_i$mLogitCropland != postBayes_i$mLogitCropland)))
  
  print(any(fullBayes_i$mPointwiseLikelihood != postBayes_i$mPointwiseLikelihood))
  # print(paste('head(fullBayes_i$mPointwiseLikelihood)'))
  knitr::kable(head(fullBayes_i$mPointwiseLikelihood), format = 'html')
  # print(paste('head(postBayes_i$mPointwiseLikelihood)'))
  knitr::kable(head(postBayes_i$mPointwiseLikelihood), format = 'html')
  
  print(paste('any(fullBayes_i$mSerialNumber != postBayes_i$mSerialNumber))',
               any(fullBayes_i$mSerialNumber != postBayes_i$mSerialNumber)))
  
  print(paste('any(fullBayes_i$mRegion != postBayes_i$mRegion))',
                any(fullBayes_i$mRegion != postBayes_i$mRegion)))
  
  print(paste('any(fullBayes_i$mShareWeights != postBayes_i$mShareWeights))',
               any(fullBayes_i$mShareWeights != postBayes_i$mShareWeights)))
  
  print(paste('any(fullBayes_i$mCalibrateShareWt != postBayes_i$mCalibrateShareWt))',
              any(fullBayes_i$mCalibrateShareWt != postBayes_i$mCalibrateShareWt)))
  
  print(paste('any(fullBayes_i$mExpectationType != postBayes_i$mExpectationType))',
               any(fullBayes_i$mExpectationType != postBayes_i$mExpectationType)))
  
  print(paste('any(fullBayes_i$mSubRegion != postBayes_i$mSubRegion))',
               any(fullBayes_i$mSubRegion != postBayes_i$mSubRegion)))
  
  print(paste('any(fullBayes_i$mLogitAgroForest != postBayes_i$mLogitAgroForest))',
               any(fullBayes_i$mLogitAgroForest != postBayes_i$mLogitAgroForest)))
  
  print(paste('any(fullBayes_i$mLogPost != postBayes_i$mLogPost))',
               any(fullBayes_i$mLogPost != postBayes_i$mLogPost)))
  # print(paste('head(fullBayes_i$mLogPost)'))
  knitr::kable(head(fullBayes_i$mLogPost), format = 'html')
  # print(paste('head(postBayes_i$mLogPost)'))
  knitr::kable(head(postBayes_i$mLogPost), format = 'html')
  
  print(paste('any(fullBayes_i$mLinearYears != postBayes_i$mLinearYears))',
               any(fullBayes_i$mLinearYears != postBayes_i$mLinearYears)))
  
  print(paste('any(fullBayes_i$mLaggedShareOld != postBayes_i$mLaggedShareOld))',
               any(fullBayes_i$mLaggedShareOld != postBayes_i$mLaggedShareOld)))
  
  print(paste('any(fullBayes_i$mOutputDir != postBayes_i$mOutputDir))',
               any(fullBayes_i$mOutputDir != postBayes_i$mOutputDir)))
  
  print(paste('any(fullBayes_i$mFileName != postBayes_i$mFileName))',
               any(fullBayes_i$mFileName != postBayes_i$mFileName)))
  
  print(paste('any(fullBayes_i$mLogitUseDefault != postBayes_i$mLogitUseDefault))',
               any(fullBayes_i$mLogitUseDefault != postBayes_i$mLogitUseDefault)))
  
  print(paste('any(fullBayes_i$mUseZeroCost != postBayes_i$mUseZeroCost))',
              any(fullBayes_i$mUseZeroCost != postBayes_i$mUseZeroCost)))
  
  print(paste('any(fullBayes_i$mScenarioName != postBayes_i$mScenarioName)', 
              any(fullBayes_i$mScenarioName != postBayes_i$mScenarioName)))
```

# Compare pre bayes, post bayes, and full bayes

Comparison is across all 10 runs (N=2 x 5 expectations).

```{r}
# #############################################################################
## Investigate waic
# #############################################################################
  
# run the scenObjects pre and post through waic
  
knitr::kable(waic(fullBayes), format = 'html')
  
knitr::kable(waic(scenObjectsBayes), format = 'html')
  
knitr::kable(waic(scenObjects), format = 'html') # prebayes

knitr::kable(waic(x[[2]]), format = 'html') # should be identical to scenObjects, just making sure
# run_bayes didn't somehow touch scenObjects and overwrite anythign
```  


The good news is that  it looks like the code isn't triggering the `run_bayes` call in `grand_table`:  Based on the above,
for the `preBayes` results that weren't touched by `run_bayes` at all (ie came out of the truncated `run_ensemble_no_bayes`), 
these runs all have `mLogPost` entries of size > 0. 

The `run_bayes` call in `grand_table` only gets triggered if `length(mLogPost) == 0`. This is true for the call to `run_bayes` in `waic` as well; further, in both `grand_table` and `waic`, the call to `run_bayes` comes with a warning which did not get printed here, suggesting `run_bayes` was not called.

```{r}
# #############################################################################
## Investigate grand_table
# #############################################################################
  
knitr::kable(grand_table(fullBayes), format = 'html')
  
knitr::kable(grand_table(scenObjectsBayes), format = 'html')

knitr::kable(grand_table(scenObjects), format = 'html')
  
knitr::kable(grand_table(x[[2]]), format = 'html')

```


```{r}
# #############################################################################
## Investigate grand_table
# #############################################################################
  
knitr::kable(MAP(grand_table(fullBayes)), format = 'html')
  
knitr::kable(MAP(grand_table(scenObjectsBayes)), format = 'html')

knitr::kable(MAP(grand_table(scenObjects)), format = 'html')
  
knitr::kable(MAP(grand_table(x[[2]])), format = 'html')

```



# TODO

- Since `preBayes` is identical to `postBayes` for every run coming from the truncated `run_ensemble_no_bayes` and since `post_Bayes` is identical to every `fullBayes` run coming from `run_ensemble`, it follows that `run_bayes` is literally doing nothing.

- unless there is a dimension or structure to these runs that I have not tested.

- the only way to test more thoroughly would be to completely comment out calls to `run_bayes` through `run_ensemble` and `grand_table` and `waic` and compare those results to what came out of an original run. Note that the call to `run_bayes` does not appear to be triggered in either `grand_table` or `waic`, because the corresponding warning is not output either.

- maybe it isn't meant to do anything with the uniform sampling approach, and maybe it would just be useful for future MCMC things...

- Good news is that we just need to make our version of `grand_table` and `MAP` for the objective functions. I thought I had to first understand the i/o structure of `run_bayes` and _then_ the i/o structure of `grand_table` to replicate but I was mistaken.


TODO list 

1. code up `objectivefunction` options

2.  write `grand_table_objective`

3.  write `MAP_objective`

4. Remove `run_bayes` from `run_ensemble` and replace with our analysis 

5. Figure out why `run_bayes` runs with N=2 but throws error with N=4, and repeat above analysis from there.
